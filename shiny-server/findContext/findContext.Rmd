---
title: "Find Context"
runtime: shiny
output: 
html_document: 
fig_caption: yes
---

- This program allows you to find utterances that match some criteria.  Then you click on a particular utterance and it will show you the file that it appears in, which allows you to see the context around the utterance.  Scroll down to the bottom for more information.  Click [here](../) to return to toolkit page.

```{r setup, include=FALSE}
library(shinycssloaders)
require(ggplot2)

ignore = "-----"
```

```{r, echo=FALSE}

shinyApp(
  ui =  fluidPage(
       tags$script(HTML("window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-7929639-6', 'auto');
ga('set', 'contentGroup1', 'filterCombine'); 
ga('send', 'pageview');")),
    tags$script(src='https://www.google-analytics.com/analytics.js'),

    sidebarPanel(selectInput("langGroup", "Language Group: ", 
                             choices = c("Eng-UK"), width='90%')
                 ,selectInput("lang", "Language: ", 
                              choices = c("Thomas"),width='90%')
                 ,selectInput("corpus", "Corpus: ", 
                              choices = c(ignore),width='90%')
                 ,selectInput("rowunit", "Row Unit:", 
                              choices = c("Word","Utterance"), selected="Utterance",width='90%')
                 ,selectInput("maxsize", "Max Size: ", 
                              choices = c(1000,10000,100000,1000000,10000000,1000000000000),width='90%',selected=1000)
                 ,textInput("search1", "Expression1:", ".+?one's.+")
                 ,selectInput("col1", "Column1: ", choices=c(ignore), width='100%')
                 ,actionButton("gotorow", "Goto Row")
                 ,width = 3)
    ,mainPanel(withSpinner(DT::dataTableOutput("table", height = '400px')))
    ,fluidRow(column(11,h4("Context")))
    ,withSpinner(DT::dataTableOutput("results", width='800px',height = '400px'))
     ),
  server = function(input, output, session) {
    source('../childes2csv/shared3.R', local=TRUE)
    values$updateFilter = TRUE
    values$recodeUI = NULL
    values$maxsize = 1000
    values$load = TRUE
    values$forcepush=FALSE
    values$matchrows=c(1)
 #   values$fulltable<-preread
    dd <- readFileDir("Eng-UK","Thomas",ignore)

   output$results <- DT::renderDataTable(DT::datatable(values$results,options = list(pageLength = 100,lengthMenu = c(10, 100, 1000))))
  
  
    observeEvent(input$corpus,  ignoreInit=T,{
         searchForCorpusFile() 
    })
    
     proxy = DT::dataTableProxy('results',session = session)
 
    observeEvent(input$table_rows_selected,ignoreInit=T,{
        onerow=values$table[input$table_rows_selected,]
        values$results = values$fulltable[values$fulltable$file == onerow$file,]
       values$matchrows = which(values$results[,input$col1]==onerow[,input$col1])
    #   print(values$matchrows)
        DT::selectRows(proxy, values$matchrows)  
    })
    
    observeEvent(input$gotorow,ignoreInit=T,{
    pg = floor(first(values$matchrows-1)/100)+1
    print(pg)
    DT::selectPage(proxy, pg)
  })
     
     observeEvent(input$maxsize,  ignoreInit=T,{
       if (values$load){
        searchForCorpusFile()
       }
       values$load=TRUE
     })
     
     resetTable <- function(){
    if (!"ONE" %in% names(values$table) ){
      values$table$ONE = 1
    }
    cho = c(ignore,names( values$table))
    updateSelectInput(session, "col1", choices = cho,selected=ignore)
  }
  
      observeEvent(input$rowunit,{
        if (values$load){
        searchForCorpusFile()
        resetTable()
        }
        values$load=TRUE
     })
      
    
    observe({
      #      input$search1
      #      input$search2
      #      input$search3
      input$col1
 #     print("observe")
      isolate({
        values$table <- values$fulltable
        
#itai = targetroles2[grepl("tsukue itaku ",targetroles2$w,),]
#print(head(itai[,c("w","role","interloc","name","file")]))
#print(length(shichadame$who))
#file20618 = subset(targetroles2,file == "20618.xml")

        if (input$col1 %in% names(values$table) ){
          values$table[,input$col1]=as.character(values$table[,input$col1])
          values$table = values$table[!is.na(values$table[,input$col1]) & str_detect(values$table[,input$col1],input$search1),c("role",input$col1,"file", "corpus","langgrp","uID")]
          #"langtype",
        }
      })
    })
    
    roundTwo <- function(x){
      i = 1
      while(round(x,i) == 0){
        i = i+1
      }
      return(round(x,i+1))
    }

    output$downloadDataResults <- downloadHandler(
      filename = function() { 
        paste(input$langGroup,",",input$lang,",",input$corpus,"_",input$rowunit,"Counts.csv",sep="")
      },
      content <- function(file) {
        write.csv(values$results, file =file,fileEncoding = "UTF-8",quote=T)
      }
      ,contentType = "text/csv"
    )
    
    output$downloadFilter <- downloadHandler(
      filename = function() { 
        paste(input$langGroup,",",input$lang,",",input$corpus,"_",input$rowunit,"Filtered.csv",sep="")
      },
      content <- function(file) {
        values$table$REGEXPTERM = paste(input$col1,"=",input$search1,";",input$col2,"=",input$search2,";",input$col3,"=",input$search3,";",sep="")
        write.csv(values$table, file =file,fileEncoding = "UTF-8",quote=T,row.names = F)
      }
      ,contentType = "text/csv"
    )
  }
  ,options = list(width=1000,height = 1200)
)
```

- This program filters CHILDES corpora.  You first select the language group, language, corpus, and row unit that you want to use.  Max size determines the maximum size of the corpus (the server is too slow for some analyses when using the whole corpus).
- To see how this could be used to examine the u-shape curve for production of overregularized past-tense forms, go to the preset field and select U-shape Curve.  The regular expression _^(goed|went|comed|came)$_ in Expression1 is applied Column1 _w_ and that filters the Thomas corpus for cases when the four words goed, went, comed, and came were produced in the _w_ column.  Expression2 is applied to the role column and this filters all cases which the _Target_Child_ produced these words.  
- The Recode source column is _w_ and there is a list of the four words in the _w_ column.  By clicking on the Create new_w button, we can create a new column called _new_w_ with a 1 for _came_ and _went_, and 0 for overregularized _goed_ and _comed_.  You can set these values to whatever you want in order to code the distinctions that you are interested in.
- The Operate section allows us to create a variable _op_Y_M_, which has the number of months that the target child has been alive.  This is created by selecting VarA (Years variable _Y_) and VarB (Month variable _M_) and then placing _12 * VarA + VarB_ in the Equation field.
- The Combine section uses the _new_w_ variable as the dependent variable (1=irregular past tense, 0 = overregularize past tense), the Combine field is set to _mean_, and Group1 is set to age in month variable _op_Y_M_.  So the figure shows the mean proportion correct irregular past tense production over age in months of the target child.  You can see that there is a U-shape curve with an early period of correct production of irregulars, followed by overgeneralization of _-ed_, followed by correct production of irregulars.
- There is a second preset called Mean Length Utterance, which will plot the mean length in words for the Target_Child and Mother in the Thomas corpus.  It is slow to load.
- To learn more about regular expressions, look [here](https://regexone.com/lesson/introduction_abcs).  
- You can download the results or the original table using the download buttons.
- These tools are still a work in progress and you should check any results with the original CHILDES corpora.  
- This work is part of the toolkit project within the ESRC International Centre for Language and Communicative Development (LuCiD) (http://www.lucid.ac.uk/, ESRC grant [ES/L008955/1]).  Please contact [Franklin Chang](https://sites.google.com/site/sentenceproductionmodel/cv) with any questions.
- To cite these tools, please use this reference: Chang, F. (2017) The LuCiD language researcher's toolkit [Computer software]. Retrieved from http://www.lucid.ac.uk/resources/for-researchers/toolkit/


